import os
import logging
import boto3
from botocore.exceptions import ClientError
from slack_bolt import App
from slack_bolt.adapter.aws_lambda import SlackRequestHandler

logger = logging.getLogger()
logger.setLevel(logging.INFO)

app = App(
    token=os.environ.get("SLACK_BOT_TOKEN"),
    signing_secret=os.environ.get("SLACK_SIGNING_SECRET"),
    process_before_response=True,
)


def invoke_model(messages):
    """
    Invokes a bedrock model using the provided messages.

    Args:
        messages (list): A list of messages to be sent to the model.

    Returns:
        str: The output text generated by the model.

    """
    client = boto3.client("bedrock-runtime")
    modelId = os.environ.get("BEDROCK_MODEL_ID")

    try:
        logger.info(f"Invoking bedrock model: {modelId}")

        response = client.converse(
            modelId=modelId,
            messages=messages,
            system=[{"text": "Format messages using Slack flavored Markdown."}],
        )

        output_text = ""
        for content in response["output"]["message"]["content"]:
            output_text += content["text"]

        logger.info(f"Model response: {output_text}")

        token_usage = response["usage"]
        logger.info(f"Input tokens: {token_usage['inputTokens']}")
        logger.info(f"Output tokens: {token_usage['outputTokens']}")
        logger.info(f"Total tokens: {token_usage['totalTokens']}")
        logger.info(f"Stop reason: {response['stopReason']}")

        return output_text

    except (ClientError, Exception) as e:
        logging.error(f"ERROR: Can't invoke '{modelId}'. Reason: {e}")
        raise e


def respond_to_slack_within_3_seconds(body, ack):
    ack()
    logger.debug(body)


@app.message(":bug:")
def handle_debug_message(message, say):
    logger.info(f"Received debug message: {message['text']}")
    logger.info(f"Lambda function name: {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}")
    logger.info(f"Lambda version: {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}")
    logger.info(f"Lambda region: {os.environ.get('AWS_REGION')}")
    logger.info(f"Lambda memory: {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}")
    logger.info(f"Lambda log group: {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}")

    debug_info = (
        f"Current Lambda function name: {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}\n"
        f"Current Lambda function version: {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}\n"
        f"Current Lambda region: {os.environ.get('AWS_REGION')}\n"
        f"Current Lambda memory limit (MB): {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}\n"
        f"Current Lambda log group name: {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}\n"
    )

    say(debug_info)


def handle_message(body, say):
    """
    Handles incoming messages from a Slack channel and responds accordingly.

    Args:
        body (dict): The incoming message payload from Slack.
        say (function): A function provided by the Slack Bolt app to send a response message.

    Returns:
        None

    Raises:
        Exception: If an error occurs while processing the message.
    """
    logger.debug(body)

    bot_user_id = app.client.auth_test()["user_id"]
    message_text = body["event"].get("text", "")

    # Process app mention
    if f"<@{bot_user_id}>" in message_text:
        logger.info("Processing app mention")
        ts = body["event"]["ts"]

        message = [
            {
                "role": "user",
                "content": [
                    {"text": message_text.replace(f"<@{bot_user_id}>", "").strip()}
                ],
            }
        ]

        try:
            logger.info(f"Invoking model with message: {message}")
            model_response = invoke_model(message)
            say(model_response, thread_ts=ts)
            return

        except Exception as e:
            logger.error(
                f"An error occurred while processing the app mention: {str(e)}"
            )
            say(text=f"Error: {str(e)}", thread_ts=ts)

    # Process threaded conversations
    thread_ts = body["event"].get("thread_ts")
    if not thread_ts:
        logger.info("Message is not part of a thread. Skipping processing.")
        return

    channel = body["event"]["channel"]
    conversation_history = app.client.conversations_replies(
        channel=channel,
        ts=thread_ts,
        limit=100,
    )

    bot_responded_earlier = any(
        message.get("user") == bot_user_id
        for message in conversation_history["messages"]
    )

    if not bot_responded_earlier:
        logger.info("Bot has not responded earlier in the thread. Skipping processing.")
        return

    messages = []
    for message in conversation_history["messages"]:
        if message.get("user") == bot_user_id:
            messages.append(
                {"role": "assistant", "content": [{"text": message["text"]}]}
            )
        elif message.get("user"):
            messages.append({"role": "user", "content": [{"text": message["text"]}]})

    try:
        logger.info(f"Invoking model with messages: {messages}")
        model_response = invoke_model(messages)

        say(model_response, thread_ts=thread_ts)
        return

    except Exception as e:
        logger.error(f"ERROR: occurred while processing message: {str(e)}")
        say(text=f"Error: {str(e)}", thread_ts=thread_ts)


app.event("message")(ack=respond_to_slack_within_3_seconds, lazy=[handle_message])


@app.event("app_home_opened")
def handle_app_home_opened(client, event, logger):
    try:
        client.views_publish(
            user_id=event["user"],
            view={
                "type": "home",
                "callback_id": "home_view",
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*Welcome to Bedrock!* :bed: :rock:",
                        },
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "I'm here to help you interact with cutting edge AI models from leaders in the space without ever leaving the comfort of Slack!",
                        },
                    },
                    {"type": "divider"},
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "Currently supported models: https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features",
                        },
                    },
                ],
            },
        )

    except Exception as e:
        logger.error(f"ERROR: publishing home tab: {e}")


@app.error
def custom_error_handler(error, body):
    logger.exception(f"Error: {error}")
    logger.info(f"Request body: {body}")


def lambda_handler(event, context):
    slack_handler = SlackRequestHandler(app=app)
    return slack_handler.handle(event, context)
