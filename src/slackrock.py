import os
import logging
import boto3
from botocore.exceptions import ClientError
from slack_bolt import App
from slack_bolt.adapter.aws_lambda import SlackRequestHandler

logger = logging.getLogger()
logger.setLevel(logging.INFO)

app = App(
    token=os.environ.get("SLACK_BOT_TOKEN"),
    signing_secret=os.environ.get("SLACK_SIGNING_SECRET"),
    process_before_response=True,
)


def invoke_model(messages):
    """
    Invokes a bedrock model using the provided messages.

    Args:
        messages (list): A list of messages to be sent to the model.

    Returns:
        str: The output text generated by the model.

    """
    client = boto3.client("bedrock-runtime")
    modelId = os.environ.get("BEDROCK_MODEL_ID")

    try:
        logger.info(f"Invoking bedrock model: {modelId}")

        response = client.converse(
            modelId=modelId,
            messages=messages,
            system=[{"text": "Format messages using Slack flavored Markdown."}],
        )

        output_text = ""
        for content in response["output"]["message"]["content"]:
            output_text += content["text"]

        logger.info(f"Model response: {output_text}")

        token_usage = response["usage"]
        logger.info(f"Input tokens: {token_usage['inputTokens']}")
        logger.info(f"Output tokens: {token_usage['outputTokens']}")
        logger.info(f"Total tokens: {token_usage['totalTokens']}")
        logger.info(f"Stop reason: {response['stopReason']}")

        return output_text

    except (ClientError, Exception) as e:
        logging.error(f"ERROR: Can't invoke '{modelId}'. Reason: {e}")
        raise e


def respond_to_slack_within_3_seconds(body, ack):
    ack()
    logger.debug(body)


def handle_app_mention(say, body):
    """
    Handle the event when the Slack app is mentioned in a message.

    Args:
        say (callable): A function provided by the Slack API to send a response message.
        body (dict): The event data received from Slack, containing information about the mention.

    Returns:
        None

    Raises:
        Exception: If an error occurs while processing the message or invoking the model.

    This function performs the following steps:
    1. Retrieves the bot user ID, channel ID, message text, and thread timestamp from the event data.
    2. Removes the bot mention from the message text.
    3. Invokes the model with the user's message.
    4. Posts the model's response to the Slack channel.
    5. Logs any errors that occur during the process.
    """

    bot_user_id = app.client.auth_test()["user_id"]
    channel_id = body["event"]["channel"]
    message_text = body["event"]["text"]
    thread_ts = body["event"]["ts"]

    mention = f"<@{bot_user_id}>"
    message = message_text.replace(mention, "").strip()

    logger.info(f"Channel ID: {channel_id}")
    logger.info(f"Thread TS: {thread_ts}")

    try:
        messages = [{"role": "user", "content": [{"text": message}]}]
        logger.info(f"Invoking model with messages: {messages}")

        model_response = invoke_model(messages)

        say(model_response, thread_ts=thread_ts)
        logger.info(f"Posted response to channel: {channel_id}")

    except Exception as e:
        logger.error(f"An error occurred while processing the message: {str(e)}")
        say(text=f"Error: {str(e)}", thread_ts=thread_ts)


app.event("app_mention")(
    ack=respond_to_slack_within_3_seconds, lazy=[handle_app_mention]
)


@app.message(":bug:")
def handle_debug_message(message, say):
    logger.info(f"Received debug message: {message['text']}")
    logger.info(f"Lambda function name: {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}")
    logger.info(f"Lambda version: {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}")
    logger.info(f"Lambda region: {os.environ.get('AWS_REGION')}")
    logger.info(f"Lambda memory: {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}")
    logger.info(f"Lambda log group: {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}")

    debug_info = (
        f"Current Lambda function name: {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}\n"
        f"Current Lambda function version: {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}\n"
        f"Current Lambda region: {os.environ.get('AWS_REGION')}\n"
        f"Current Lambda memory limit (MB): {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}\n"
        f"Current Lambda log group name: {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}\n"
    )

    say(debug_info)


def handle_message(body, say):
    """
    Handles incoming messages from a Slack channel and responds accordingly.

    Args:
        body (dict): The incoming message payload from Slack.
        say (function): A function provided by the Slack Bolt app to send a response message.

    Returns:
        None

    Raises:
        Exception: If an error occurs while processing the message.

    This function performs the following steps:
    1. Extracts relevant information from the incoming message payload, such as the thread timestamp, bot ID, and channel ID.
    2. Checks if the message is part of a thread and if the bot has responded earlier in the thread.
    3. Retrieves the conversation history from Slack for the given thread.
    4. Constructs a list of messages with their roles (user or assistant) and content.
    5. Invokes a model with the constructed list of messages to generate a response.
    6. Sends the generated response back to the Slack channel using the provided `say` function.
    7. If an exception occurs during the process, it logs the error and sends an error message to the Slack channel.
    """
    logger.debug(body)

    event = body["event"]
    thread_ts = event.get("thread_ts")
    bot_id = app.client.auth_test()["bot_id"]
    channel = event["channel"]

    if not thread_ts:
        logger.info("Message is not part of a thread. Skipping processing.")
        return

    conversation_history = app.client.conversations_replies(
        channel=channel,
        ts=thread_ts,
        limit=100,
    )

    bot_responded_earlier = any(
        message.get("bot_id") == bot_id for message in conversation_history["messages"]
    )

    if not bot_responded_earlier:
        logger.info("Bot has not responded earlier in the thread. Skipping processing.")
        return

    messages = []
    for message in conversation_history["messages"]:
        if message.get("bot_id") == bot_id:
            messages.append(
                {"role": "assistant", "content": [{"text": message["text"]}]}
            )
        elif message.get("user"):
            messages.append({"role": "user", "content": [{"text": message["text"]}]})

    try:
        logger.info(f"Invoking model with messages: {messages}")

        model_response = invoke_model(messages)

        say(model_response, thread_ts=thread_ts)

    except Exception as e:
        logger.error(f"ERROR: occurred while processing message: {str(e)}")
        say(text=f"Error: {str(e)}", thread_ts=thread_ts)


app.event("message")(ack=respond_to_slack_within_3_seconds, lazy=[handle_message])


@app.event("app_home_opened")
def handle_app_home_opened(client, event, logger):
    try:
        client.views_publish(
            user_id=event["user"],
            view={
                "type": "home",
                "callback_id": "home_view",
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*Welcome to Bedrock!* :bed: :rock:",
                        },
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "I'm here to help you interact with cutting edge AI models from leaders in the space without ever leaving the comfort of Slack!",
                        },
                    },
                    {"type": "divider"},
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "Currently supported models: https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features",
                        },
                    },
                ],
            },
        )

    except Exception as e:
        logger.error(f"ERROR: publishing home tab: {e}")


@app.error
def custom_error_handler(error, body):
    logger.exception(f"Error: {error}")
    logger.info(f"Request body: {body}")


def lambda_handler(event, context):
    slack_handler = SlackRequestHandler(app=app)
    return slack_handler.handle(event, context)
