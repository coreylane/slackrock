import os
import logging
import boto3
from botocore.exceptions import ClientError
from slack_bolt import App
from slack_bolt.adapter.aws_lambda import SlackRequestHandler

logger = logging.getLogger()
logger.setLevel(logging.INFO)

app = App(
    token=os.environ.get("SLACK_BOT_TOKEN"),
    signing_secret=os.environ.get("SLACK_SIGNING_SECRET"),
    process_before_response=True,
)


def invoke_model(messages, user_id):
    """
    Invokes a bedrock model using the provided messages.

    Args:
        messages (list): A list of messages to be sent to the model.

    Returns:
        str: The output text generated by the model.
    """
    bedrock_client = boto3.client("bedrock-runtime")

    try:
        # Fetch user's model preference from DynamoDB
        table = get_dynamodb_table()
        response = table.get_item(Key={"user_id": user_id})
        user_model = response.get("Item", {}).get("model_id")

        # Use the user's preferred model or fall back to the default
        BEDROCK_MODEL_ID = user_model or os.environ.get("BEDROCK_MODEL_ID")

        logger.info(f"Invoking Bedrock model for user {user_id}: {BEDROCK_MODEL_ID}")

        response = bedrock_client.converse(
            messages=messages,
            modelId=BEDROCK_MODEL_ID,
            system=[{"text": "Format messages using Slack flavored Markdown."}],
        )

        output_text = "".join(
            content["text"] for content in response["output"]["message"]["content"]
        )

        logger.info(f"Model response: {output_text}")

        token_usage = response["usage"]
        logger.info(f"Input tokens: {token_usage['inputTokens']}")
        logger.info(f"Output tokens: {token_usage['outputTokens']}")
        logger.info(f"Total tokens: {token_usage['totalTokens']}")
        logger.info(f"Stop reason: {response['stopReason']}")

        return output_text

    except ClientError as e:
        logger.error(f"ERROR: Can't invoke '{BEDROCK_MODEL_ID}'. Reason: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error occurred: {e}")
        raise


def respond_to_slack_within_3_seconds(body, ack):
    ack()
    logger.debug(body)


# Print out some debug info
@app.message(":bug:")
def handle_debug_message(message, say):
    logger.info(f"Received debug message: {message['text']}")
    logger.info(f"Current Bedrock model ID: {os.environ.get('BEDROCK_MODEL_ID')}")
    logger.info(f"Lambda function name: {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}")
    logger.info(f"Lambda version: {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}")
    logger.info(f"Lambda region: {os.environ.get('AWS_REGION')}")
    logger.info(f"Lambda memory: {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}")
    logger.info(f"Lambda log group: {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}")

    debug_info = (
        f"*Current Bedrock model ID:* {os.environ.get('BEDROCK_MODEL_ID')}\n"
        f"*Current Lambda function name:* {os.environ.get('AWS_LAMBDA_FUNCTION_NAME')}\n"
        f"*Current Lambda function version:* {os.environ.get('AWS_LAMBDA_FUNCTION_VERSION')}\n"
        f"*Current Lambda region:* {os.environ.get('AWS_REGION')}\n"
        f"*Current Lambda memory limit (MB):* {os.environ.get('AWS_LAMBDA_FUNCTION_MEMORY_SIZE')}\n"
        f"*Current Lambda log group name:* {os.environ.get('AWS_LAMBDA_LOG_GROUP_NAME')}\n"
    )

    say(debug_info, thread_ts=message["ts"])


def handle_message(body, say):
    """
    Handles incoming messages from a Slack channel and responds accordingly.

    Args:
        body (dict): The incoming message payload from Slack.
        say (function): A function provided by the Slack Bolt app to send a response message.

    Returns:
        None

    Raises:
        Exception: If an error occurs while processing the message.
    """
    logger.debug(body)

    bot_user_id = app.client.auth_test()["user_id"]
    message_text = body["event"].get("text", "")

    # Process app mentions in public & private channels
    if f"<@{bot_user_id}>" in message_text:
        logger.info("Processing app mention")
        ts = body["event"]["ts"]

        message = [
            {
                "role": "user",
                "content": [
                    {"text": message_text.replace(f"<@{bot_user_id}>", "").strip()}
                ],
            }
        ]

        try:
            logger.info(f"Invoking model with message: {message}")
            model_response = invoke_model(message, body["event"]["user"])
            say(model_response, thread_ts=ts)
            return

        except Exception as e:
            logger.error(
                f"An error occurred while processing the app mention: {str(e)}"
            )
            say(text=f"Error: {str(e)}", thread_ts=ts)

    # Process a fresh DM
    if "thread_ts" not in body["event"] and body["event"]["channel_type"] == "im":
        logger.info(f"Received fresh direct message: {body['event']}")
        message_text = body["event"].get("text", "")
        ts = body["event"]["ts"]

        message = [
            {
                "role": "user",
                "content": [{"text": message_text}],
            }
        ]

        try:
            logger.info(f"Invoking model with message: {message}")
            model_response = invoke_model(message, body["event"]["user"])
            say(model_response, thread_ts=ts)
            return

        except Exception as e:
            logger.error(f"An error occurred while processing direct message: {str(e)}")
            say(text=f"Error: {str(e)}", thread_ts=ts)

    # Process threaded conversations in public/private channels & direct messages
    thread_ts = body["event"].get("thread_ts")
    if not thread_ts:
        logger.info("Message is not part of a thread. Skipping processing.")
        return

    channel = body["event"]["channel"]
    conversation_history = app.client.conversations_replies(
        channel=channel,
        ts=thread_ts,
        limit=100,
    )

    # Don't get involved in other user's threads
    bot_responded_earlier = any(
        message.get("user") == bot_user_id
        for message in conversation_history["messages"]
        if message.get("user") is not None
    )

    if not bot_responded_earlier:
        logger.info("Bot has not responded earlier in the thread. Skipping processing.")
        return

    messages = [
        {
            "role": "assistant" if message.get("user") == bot_user_id else "user",
            "content": [{"text": message["text"]}],
        }
        for message in conversation_history["messages"]
        if message.get("user") is not None
    ]

    try:
        logger.info(f"Processing threaded conversation: {messages}")
        model_response = invoke_model(messages, body["event"]["user"])

        say(model_response, thread_ts=thread_ts)
        return

    except Exception as e:
        logger.error(f"Error while processing threaded conversation: {str(e)}")
        say(text=f"Error: {str(e)}", thread_ts=thread_ts)


app.event("message")(ack=respond_to_slack_within_3_seconds, lazy=[handle_message])


# Lazy initialization for DynamoDB
dynamodb = None
table = None


def get_dynamodb_table():
    global dynamodb, table
    if table is None:
        dynamodb = boto3.resource("dynamodb")
        table = dynamodb.Table(os.environ.get("DYNAMODB_TABLE_NAME"))
    return table


def get_bedrock_models():
    """
    Fetch the list of currently enabled AWS Bedrock models that support Converse API and System prompts.
    Returns a list of dictionaries with shortened display names for the dropdown.

    Returns:
        list: A list of dictionaries containing model information for Slack dropdown.
    """
    # List of AWS Bedrock models that 1) support Converse API & 2) Support System prompts
    # https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features
    bedrock_models = [
        ("anthropic.claude-3-5-sonnet-20240620-v1:0", "Anthropic Claude 3.5 Sonnet"),
        ("anthropic.claude-3-haiku-20240307-v1:0", "Anthropic Claude 3 Haiku"),
        ("anthropic.claude-3-sonnet-20240229-v1:0", "Anthropic Claude 3 Sonnet"),
        ("cohere.command-r-plus-v1:0", "Cohere Command R+"),
        ("cohere.command-r-v1:0", "Cohere Command R"),
        ("meta.llama2-13b-chat-v1", "Meta Llama 2 Chat 13B"),
        ("meta.llama2-70b-chat-v1", "Meta Llama 2 Chat 70B"),
        ("meta.llama3-70b-instruct-v1:0", "Meta Llama 3 70b Instruct"),
        ("meta.llama3-8b-instruct-v1:0", "Meta Llama 3 8b Instruct"),
        ("mistral.mistral-large-2402-v1:0", "Mistral Large"),
        ("mistral.mistral-small-2402-v1:0", "Mistral Small"),
    ]

    return [
        {"text": {"type": "plain_text", "text": display_name}, "value": model_id}
        for model_id, display_name in bedrock_models
    ]


@app.event("app_home_opened")
def update_home_tab(client, event):
    user_id = event["user"]
    try:
        # Fetch user's current model preference
        table = get_dynamodb_table()
        response = table.get_item(Key={"user_id": user_id})
        current_model_id = response.get("Item", {}).get("model_id", "Not set")

        # Get the display name for the current model
        current_model_display = next(
            (
                model["text"]["text"]
                for model in get_bedrock_models()
                if model["value"] == current_model_id
            ),
            "Not set",
        )

        # Construct the home tab view
        client.views_publish(
            user_id=user_id,
            view={
                "type": "home",
                "callback_id": "home_view",
                "blocks": [
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": "Welcome to Slackrock!",
                        },
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "*Slackrock* is a conversational AI assistant powered by Amazon Bedrock & your favorite frontier models.",
                        },
                    },
                    {"type": "divider"},
                    {
                        "type": "header",
                        "text": {
                            "type": "plain_text",
                            "text": "Choose your model",
                        },
                    },
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"Your current Bedrock model: *{current_model_display}*",
                        },
                    },
                    {
                        "type": "context",
                        "elements": [
                            {
                                "type": "mrkdwn",
                                "text": "Choose your preferred Bedrock model from the dropdown below.",
                            }
                        ],
                    },
                    {
                        "type": "actions",
                        "elements": [
                            {
                                "type": "static_select",
                                "placeholder": {
                                    "type": "plain_text",
                                    "text": "Select a Bedrock model",
                                },
                                "options": get_bedrock_models(),
                                "action_id": "select_model",
                            }
                        ],
                    },
                    {"type": "divider"},
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": "Slackrock only supports Bedrock models that 1) Support the Converse API 2) Support system prompts. For more information on supported models, visit: https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html#conversation-inference-supported-models-features",
                        },
                    },
                ],
            },
        )
    except Exception as e:
        logger.error(f"Error publishing home tab: {e}")


@app.action("select_model")
def handle_model_selection(ack, body, say):
    ack()
    user_id = body["user"]["id"]
    selected_model = body["actions"][0]["selected_option"]["value"]
    selected_model_display = body["actions"][0]["selected_option"]["text"]["text"]

    try:
        # Store the user's selection in DynamoDB
        table = get_dynamodb_table()
        table.put_item(Item={"user_id": user_id, "model_id": selected_model})

        # Update the home tab to reflect the new selection
        update_home_tab(say.client, {"user": user_id})

        # Send a confirmation message
        say(
            channel=user_id,
            text=f":brain: Your Bedrock model preference has been updated to: *{selected_model_display}*",
        )

    except Exception as e:
        logger.error(f"Error updating model preference: {e}")
        say(
            channel=user_id,
            text=":warning: There was an error saving your preference. Please try again later.",
        )


@app.error
def custom_error_handler(error, body):
    logger.exception(f"Error: {error}")
    logger.info(f"Request body: {body}")


def lambda_handler(event, context):
    slack_handler = SlackRequestHandler(app=app)
    return slack_handler.handle(event, context)
